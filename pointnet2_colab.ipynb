{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pointnet2_colab.ipynb","version":"0.3.2","provenance":[{"file_id":"1SYmHSnJZscK6M8Qdj2s6TCVAgYD0_pXc","timestamp":1543591806486}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"9_eGvghSQVgi","colab_type":"text"},"cell_type":"markdown","source":["**Prepare library (tensorflow 1.4.1)**"]},{"metadata":{"id":"kaA15Hc2ek1z","colab_type":"code","colab":{}},"cell_type":"code","source":["# reinstall tensorflow to 1.4.4\n","!pip install tensorflow-gpu==1.4.1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"InBfVZ5fQbUL","colab_type":"text"},"cell_type":"markdown","source":["**Prepare dataset and pull pointnet2 from github**"]},{"metadata":{"id":"OdQwoRbLU6gZ","colab_type":"code","outputId":"674419ce-9441-45b6-e907-a0268ddc563c","executionInfo":{"status":"ok","timestamp":1539117305205,"user_tz":-120,"elapsed":11336,"user":{"displayName":"Mohammad Wasil","photoUrl":"","userId":"16449178055024790713"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"cell_type":"code","source":["# completely pull from github\n","import os\n","os.chdir('/content')\n","!rm -rf pointnet2\n","!git clone -b colab https://github.com/mhwasil/pointnet2.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'pointnet2'...\n","remote: Enumerating objects: 420, done.\u001b[K\n","Receiving objects:   0% (1/420)   \rReceiving objects:   1% (5/420)   \rReceiving objects:   2% (9/420)   \rReceiving objects:   3% (13/420)   \rReceiving objects:   4% (17/420)   \rReceiving objects:   5% (21/420)   \rReceiving objects:   6% (26/420)   \rReceiving objects:   7% (30/420)   \rReceiving objects:   8% (34/420)   \rReceiving objects:   9% (38/420)   \rReceiving objects:  10% (42/420)   \rReceiving objects:  11% (47/420)   \rReceiving objects:  12% (51/420)   \rReceiving objects:  13% (55/420)   \rReceiving objects:  14% (59/420)   \rReceiving objects:  15% (63/420)   \rReceiving objects:  16% (68/420)   \rReceiving objects:  17% (72/420)   \rReceiving objects:  18% (76/420)   \rReceiving objects:  19% (80/420)   \rReceiving objects:  20% (84/420)   \rReceiving objects:  21% (89/420)   \rReceiving objects:  22% (93/420)   \rReceiving objects:  23% (97/420)   \rReceiving objects:  24% (101/420)   \rReceiving objects:  25% (105/420)   \rReceiving objects:  26% (110/420)   \rReceiving objects:  27% (114/420)   \rReceiving objects:  28% (118/420)   \rReceiving objects:  29% (122/420)   \rReceiving objects:  30% (126/420)   \rReceiving objects:  31% (131/420)   \rReceiving objects:  32% (135/420)   \rReceiving objects:  33% (139/420)   \rReceiving objects:  34% (143/420)   \rReceiving objects:  35% (147/420)   \rReceiving objects:  36% (152/420)   \rReceiving objects:  37% (156/420)   \rReceiving objects:  38% (160/420)   \rReceiving objects:  39% (164/420)   \rReceiving objects:  40% (168/420)   \rReceiving objects:  41% (173/420)   \rReceiving objects:  42% (177/420)   \rReceiving objects:  43% (181/420)   \rReceiving objects:  44% (185/420)   \rReceiving objects:  45% (189/420)   \rReceiving objects:  46% (194/420)   \rReceiving objects:  47% (198/420)   \rReceiving objects:  48% (202/420)   \rReceiving objects:  49% (206/420)   \rReceiving objects:  50% (210/420)   \rReceiving objects:  51% (215/420)   \rReceiving objects:  52% (219/420)   \rReceiving objects:  53% (223/420)   \rReceiving objects:  54% (227/420)   \rReceiving objects:  55% (231/420)   \rReceiving objects:  56% (236/420)   \rReceiving objects:  57% (240/420)   \rReceiving objects:  58% (244/420)   \rReceiving objects:  59% (248/420)   \rReceiving objects:  60% (252/420)   \rReceiving objects:  61% (257/420)   \rReceiving objects:  62% (261/420)   \rReceiving objects:  63% (265/420)   \rReceiving objects:  64% (269/420)   \rReceiving objects:  65% (273/420)   \rReceiving objects:  66% (278/420)   \rReceiving objects:  67% (282/420)   \rReceiving objects:  68% (286/420)   \rReceiving objects:  69% (290/420)   \rReceiving objects:  70% (294/420)   \rReceiving objects:  71% (299/420)   \rReceiving objects:  72% (303/420)   \rReceiving objects:  73% (307/420)   \rReceiving objects:  74% (311/420)   \rReceiving objects:  75% (315/420)   \rReceiving objects:  76% (320/420)   \rReceiving objects:  77% (324/420)   \rReceiving objects:  78% (328/420)   \rReceiving objects:  79% (332/420)   \rReceiving objects:  80% (336/420)   \rReceiving objects:  81% (341/420)   \rReceiving objects:  82% (345/420)   \rReceiving objects:  83% (349/420)   \rReceiving objects:  84% (353/420)   \rReceiving objects:  85% (357/420)   \rReceiving objects:  86% (362/420)   \rReceiving objects:  87% (366/420)   \rremote: Total 420 (delta 0), reused 0 (delta 0), pack-reused 420\u001b[K\n","Receiving objects: 100% (420/420), 794.41 KiB | 2.28 MiB/s, done.\n","Resolving deltas: 100% (250/250), done.\n"],"name":"stdout"}]},{"metadata":{"id":"xlCvkq-Wk-o8","colab_type":"code","colab":{}},"cell_type":"code","source":["# partially pull from github\n","#os.chdir('/content/pointnet2')\n","#!git pull origin colab"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GUSY-cmiVbES","colab_type":"code","outputId":"3b9c7333-200a-4799-c782-ab7165c86537","executionInfo":{"status":"ok","timestamp":1539117314882,"user_tz":-120,"elapsed":3986,"user":{"displayName":"Mohammad Wasil","photoUrl":"","userId":"16449178055024790713"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["# navigate to pointnet2 folder\n","os.chdir('/content/pointnet2')\n","!ls "],"execution_count":0,"outputs":[{"output_type":"stream","text":["data\t     LICENSE\t\t     models\tscannet\t\t    train.py\n","doc\t     modelnet_dataset.py     part_seg\ttf_ops\t\t    utils\n","evaluate.py  modelnet_h5_dataset.py  README.md\ttrain_multi_gpu.py\n"],"name":"stdout"}]},{"metadata":{"id":"wUTtRbIRR6AG","colab_type":"text"},"cell_type":"markdown","source":["**Download modelnet40 (shapenet)**"]},{"metadata":{"id":"_LzV98ueP2H-","colab_type":"code","colab":{}},"cell_type":"code","source":["# download normal dataset\n","!wget https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip --no-check-certificate"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FMpYgzrnP4-H","colab_type":"code","colab":{}},"cell_type":"code","source":["# run this for the first time and the run the train.py again\n","!ls\n","# uncomment this for hdf5\n","#!unzip modelnet40_ply_hdf5_2048\n","#!mv modelnet40_ply_hdf5_2048/ data/\n","\n","# uncomment this for normal dataset\n","!wget https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip --no-check-certificate\n","!unzip modelnet40_normal_resampled.zip\n","!mv modelnet40_normal_resampled/ data/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b5X7anr1oBze","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"TldezuVlR_3N","colab_type":"text"},"cell_type":"markdown","source":["**Prepare our own dataset and download from google drive**"]},{"metadata":{"id":"1rUOavY2o_le","colab_type":"code","colab":{}},"cell_type":"code","source":["#!pip install PyDrive\n","\n","#import os\n","#from pydrive.auth import GoogleAuth\n","#from pydrive.drive import GoogleDrive\n","#from google.colab import auth\n","#from oauth2client.client import GoogleCredentials"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mn1sh5hmpBrj","colab_type":"code","colab":{}},"cell_type":"code","source":["#auth.authenticate_user()\n","#gauth = GoogleAuth()\n","#gauth.credentials = GoogleCredentials.get_application_default()\n","#drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ORIWpyiE43xq","colab_type":"code","colab":{}},"cell_type":"code","source":["# download atwork datset\n","#download = drive.CreateFile({'id': '1xS3tnWQbiJLPE9IabhtX9sS45rGn9gGexE'})\n","#download.GetContentFile('gezebo_dataset_v2.zip')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9XgGGNd1Y_h6","colab_type":"code","colab":{}},"cell_type":"code","source":["#!unzip gezebo_dataset_v2.zip\n","#!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"twALVkRGmsVM","colab_type":"code","colab":{}},"cell_type":"code","source":["# real dataset\n","# replace with your id from google drive\n","#download = drive.CreateFile({'id': '1wJIIzkZererFsMYviSmLu-Nk9u1i4tcLp5DBb'})\n","#download.GetContentFile('real_dataset.zip')\n","#!ls "],"execution_count":0,"outputs":[]},{"metadata":{"id":"D4Kdijh-SPkb","colab_type":"code","colab":{}},"cell_type":"code","source":["# download shapenet stanford datset (different dataset from previous one)\n","#download = drive.CreateFile({'id': '1Ezoqz7bAokY3eaw8LswRr0_l_yBAIvKBMaKd'})\n","#download.GetContentFile('shapenet_dataset.zip')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2YnPcqZ-pJmh","colab_type":"code","colab":{}},"cell_type":"code","source":["#!unzip dataset_generator.zip\n","#!unzip shapenet_dataset.zip\n","#!ls\n","#!unzip dataset_generator.zip\n","#!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dD89mQLAOtD1","colab_type":"text"},"cell_type":"markdown","source":["**Upload your own dataset directly**"]},{"metadata":{"id":"tay19MbOYku1","colab_type":"code","outputId":"53bab383-f100-49be-f47c-b29747dbf19d","executionInfo":{"status":"ok","timestamp":1533916529894,"user_tz":-120,"elapsed":15177,"user":{"displayName":"Mohammad Wasil","photoUrl":"//lh5.googleusercontent.com/-JLhvywYz9ws/AAAAAAAAAAI/AAAAAAAAGAI/Qh1Tzhjb9Kw/s50-c-k-no/photo.jpg","userId":"100717550650637687476"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":99}},"cell_type":"code","source":["os.chdir(\"data/modelnet40_normal_resampled/\")\n","from google.colab import files\n","files.upload()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-1c64977a-02f8-43e8-b493-3e5058a5258f\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-1c64977a-02f8-43e8-b493-3e5058a5258f\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving shape_names.txt to shape_names.txt\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'shape_names.txt': b'bathtub\\nbed\\nchair\\ndesk\\ndresser\\nmonitor\\nnight_stand\\nsofa\\ntable\\ntoilet\\n'}"]},"metadata":{"tags":[]},"execution_count":39}]},{"metadata":{"id":"HCSurLRiYlf9","colab_type":"code","outputId":"62f8f997-1539-49e3-c1bd-4cdcc1636d7c","executionInfo":{"status":"ok","timestamp":1533913856394,"user_tz":-120,"elapsed":6949,"user":{"displayName":"Mohammad Wasil","photoUrl":"//lh5.googleusercontent.com/-JLhvywYz9ws/AAAAAAAAAAI/AAAAAAAAGAI/Qh1Tzhjb9Kw/s50-c-k-no/photo.jpg","userId":"100717550650637687476"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":99}},"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-15a38c72-84dd-463d-9751-3ed864656211\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-15a38c72-84dd-463d-9751-3ed864656211\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving shape_names.txt to shape_names (1).txt\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'shape_names.txt': b'bathtub\\nbed\\nchair\\ndesk\\ndresser\\nmonitor\\nnight_stand\\nsofa\\ntable\\ntoilet\\n'}"]},"metadata":{"tags":[]},"execution_count":21}]},{"metadata":{"id":"ha6jUGK0sMvB","colab_type":"text"},"cell_type":"markdown","source":["**Import libraries**"]},{"metadata":{"id":"WWNbSqhjnstX","colab_type":"code","outputId":"17f65118-665c-44e3-fd1b-a6b77daf46ca","executionInfo":{"status":"ok","timestamp":1539117489942,"user_tz":-120,"elapsed":4573,"user":{"displayName":"Mohammad Wasil","photoUrl":"","userId":"16449178055024790713"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"cell_type":"code","source":["import os\n","import os.path\n","import json\n","import sys\n","BASE_DIR = os.path.dirname(os.path.abspath('__file__'))\n","ROOT_DIR = BASE_DIR\n","sys.path.append(BASE_DIR)\n","sys.path.append(os.path.join(ROOT_DIR, 'models'))\n","sys.path.append(os.path.join(ROOT_DIR, 'utils'))\n","\n","import argparse\n","import socket\n","import importlib\n","import time\n","import scipy.misc\n","\n","import numpy as np\n","import tensorflow as tf\n","import provider\n","import modelnet_dataset\n","import modelnet_h5_dataset"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n","  return f(*args, **kwds)\n"],"name":"stderr"}]},{"metadata":{"id":"W70FR09vsbZ4","colab_type":"text"},"cell_type":"markdown","source":["**Initialize the models**"]},{"metadata":{"id":"CKBEgaW3saIa","colab_type":"code","outputId":"5ed29149-a6ca-4421-f1e5-db2ee8ba9717","executionInfo":{"status":"ok","timestamp":1539117496501,"user_tz":-120,"elapsed":1878,"user":{"displayName":"Mohammad Wasil","photoUrl":"","userId":"16449178055024790713"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["\"\"\"\n","    PointNet++ Model for point clouds classification\n","\"\"\"\n","\n","import tf_util\n","from pointnet_util import pointnet_sa_module\n","\n","def placeholder_inputs(batch_size, num_point):\n","    pointclouds_pl = tf.placeholder(tf.float32, shape=(batch_size, num_point, 3))\n","    labels_pl = tf.placeholder(tf.int32, shape=(batch_size))\n","    return pointclouds_pl, labels_pl\n","\n","def get_model(point_cloud, is_training, bn_decay=None):\n","    \"\"\" Classification PointNet, input is BxNx3, output Bx40 \"\"\"\n","    batch_size = point_cloud.get_shape()[0].value\n","    num_point = point_cloud.get_shape()[1].value\n","    end_points = {}\n","    l0_xyz = point_cloud\n","    l0_points = None\n","    end_points['l0_xyz'] = l0_xyz\n","\n","    # Set abstraction layers\n","    # Note: When using NCHW for layer 2, we see increased GPU memory usage (in TF1.4).\n","    # So we only use NCHW for layer 1 until this issue can be resolved.\n","    l1_xyz, l1_points, l1_indices = pointnet_sa_module(l0_xyz, l0_points, npoint=512, \n","                                    radius=0.2, nsample=32, mlp=[64,64,128], mlp2=None, \n","                                    group_all=False, is_training=is_training, bn_decay=bn_decay, \n","                                    scope='layer1', use_nchw=True)\n","    \n","    l2_xyz, l2_points, l2_indices = pointnet_sa_module(l1_xyz, l1_points, npoint=128, radius=0.4, \n","                                    nsample=64, mlp=[128,128,256], mlp2=None, group_all=False, \n","                                    is_training=is_training, bn_decay=bn_decay, scope='layer2')\n","    \n","    l3_xyz, l3_points, l3_indices = pointnet_sa_module(l2_xyz, l2_points, npoint=None, radius=None, \n","                                    nsample=None, mlp=[256,512,1024], mlp2=None, group_all=True, \n","                                    is_training=is_training, bn_decay=bn_decay, scope='layer3')\n","\n","    # Fully connected layers\n","    net = tf.reshape(l3_points, [batch_size, -1])\n","    net = tf_util.fully_connected(net, 512, bn=True, is_training=is_training, scope='fc1', bn_decay=bn_decay)\n","    net = tf_util.dropout(net, keep_prob=0.5, is_training=is_training, scope='dp1')\n","    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training, scope='fc2', bn_decay=bn_decay)\n","    net = tf_util.dropout(net, keep_prob=0.5, is_training=is_training, scope='dp2')\n","    net = tf_util.fully_connected(net, 40, activation_fn=None, scope='fc3')\n","\n","    return net, end_points\n","\n","\n","def get_loss(pred, label, end_points):\n","    \"\"\" pred: B*NUM_CLASSES,\n","        label: B, \"\"\"\n","    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n","    classify_loss = tf.reduce_mean(loss)\n","    tf.summary.scalar('classify loss', classify_loss)\n","    tf.add_to_collection('losses', classify_loss)\n","    return classify_loss\n","\n","\n","if __name__=='__main__':\n","    with tf.Graph().as_default():\n","        inputs = tf.zeros((16,600,3))\n","        output, _ = get_model(inputs, tf.constant(True))\n","        print(output)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tensor(\"fc3/BiasAdd:0\", shape=(16, 40), dtype=float32)\n"],"name":"stdout"}]},{"metadata":{"id":"ryqVJ-aUsaRX","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"y4wgSjJ3k7M3","colab_type":"text"},"cell_type":"markdown","source":["**Load the dataset**"]},{"metadata":{"id":"gyWQ4ISXk6bS","colab_type":"code","colab":{}},"cell_type":"code","source":["DATASET_PATH = 'shapenet_dataset/train_data_combined'\n","DATASET_NAME = 'shapenet'\n","CLASS_LABEL_LIST ='shape_names.txt'\n","# change this to False for hdf5 dataset\n","\n","#DATASET_PATH = 'gazebo_dataset_v2/gazebo_dataset_v2'\n","#DATASET_NAME = 'gazebo'\n","#CLASS_LABEL_LIST ='shape_names.txt'\n","\n","normal = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RyyNTkOMk6hL","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 32\n","NUM_POINT = 300\n","MAX_EPOCH = 50\n","MODEL_NAME = 'pointnet2_cls_ssg'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qCzdxfDUklzX","colab_type":"text"},"cell_type":"markdown","source":["**Train the model**"]},{"metadata":{"id":"uRRkG_q-jB7R","colab_type":"code","outputId":"f84859a6-a963-4e9d-d4df-6ecb5adea4ea","executionInfo":{"status":"error","timestamp":1543591690909,"user_tz":-60,"elapsed":2700,"user":{"displayName":"Mohammad Wasil","photoUrl":"https://lh5.googleusercontent.com/-JLhvywYz9ws/AAAAAAAAAAI/AAAAAAAAGAI/Qh1Tzhjb9Kw/s64/photo.jpg","userId":"16449178055024790713"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"cell_type":"code","source":["'''\n","    Single-GPU training.\n","    Will use H5 dataset in default. If using normal, will shift to the normal dataset.\n","'''\n","import argparse\n","import math\n","from datetime import datetime\n","import h5py\n","import numpy as np\n","import tensorflow as tf\n","import socket\n","import importlib\n","import os\n","import sys\n","BASE_DIR = os.path.dirname(os.path.abspath('__file__'))\n","ROOT_DIR = BASE_DIR\n","sys.path.append(BASE_DIR)\n","sys.path.append(os.path.join(ROOT_DIR, 'models'))\n","sys.path.append(os.path.join(ROOT_DIR, 'utils'))\n","import provider\n","import tf_util\n","import modelnet_dataset\n","import modelnet_h5_dataset\n","\n","EPOCH_CNT = 0\n","\n","\n","BASE_LEARNING_RATE = 0.001\n","GPU_INDEX = 0\n","MOMENTUM = 0.9\n","OPTIMIZER = 'adam'\n","DECAY_STEP = 200000\n","DECAY_RATE = 0.7\n","\n","#DATASET_PATH = 'dataset_generator/atwork_generated_dataset'\n","#DATASET_NAME = 'atwork'\n","#MODEL_NAME = 'pointnet2_cls_ssg'\n","#normal = True\n","\n","MODEL = importlib.import_module(MODEL_NAME) # import network module\n","MODEL_FILE = os.path.join(ROOT_DIR, 'models', MODEL_NAME+'.py')\n","LOG_DIR = '/tmp/log'\n","if not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\n","os.system('cp %s %s' % (MODEL_FILE, LOG_DIR)) # bkp of model def\n","os.system('cp train.py %s' % (LOG_DIR)) # bkp of train procedure\n","LOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'w')\n","#LOG_FOUT.write(str(FLAGS)+'\\n')\n","\n","BN_INIT_DECAY = 0.5\n","BN_DECAY_DECAY_RATE = 0.5\n","BN_DECAY_DECAY_STEP = float(DECAY_STEP)\n","BN_DECAY_CLIP = 0.99\n","\n","HOSTNAME = socket.gethostname()\n","\n","# Shapenet official train/test split\n","if normal:\n","    assert(NUM_POINT<=10000)\n","    DATA_PATH = os.path.join(ROOT_DIR, DATASET_PATH)\n","    TRAIN_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='train', \n","                    normal_channel=False, batch_size=BATCH_SIZE,\n","                    class_name_path=\"shape_names.txt\", dataset=DATASET_NAME)\n","    TEST_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='test', \n","                    normal_channel=False, batch_size=BATCH_SIZE,\n","                    class_name_path=\"shape_names.txt\", dataset=DATASET_NAME)\n","#else:\n","#    assert(NUM_POINT<=2048)\n","#    TRAIN_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/train_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=True)\n","#    TEST_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/test_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=False)\n","\n","NUM_CLASSES = len(TRAIN_DATASET.classes)\n","\n","def log_string(out_str):\n","    LOG_FOUT.write(out_str+'\\n')\n","    LOG_FOUT.flush()\n","    print(out_str)\n","\n","def get_learning_rate(batch):\n","    learning_rate = tf.train.exponential_decay(\n","                        BASE_LEARNING_RATE,  # Base learning rate.\n","                        batch * BATCH_SIZE,  # Current index into the dataset.\n","                        DECAY_STEP,          # Decay step.\n","                        DECAY_RATE,          # Decay rate.\n","                        staircase=True)\n","    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n","    return learning_rate        \n","\n","def get_bn_decay(batch):\n","    bn_momentum = tf.train.exponential_decay(\n","                      BN_INIT_DECAY,\n","                      batch*BATCH_SIZE,\n","                      BN_DECAY_DECAY_STEP,\n","                      BN_DECAY_DECAY_RATE,\n","                      staircase=True)\n","    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n","    return bn_decay\n","\n","def train():\n","    with tf.Graph().as_default():\n","        with tf.device('/gpu:'+str(GPU_INDEX)):\n","            pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n","            is_training_pl = tf.placeholder(tf.bool, shape=())\n","            \n","            # Note the global_step=batch parameter to minimize. \n","            # That tells the optimizer to helpfully increment the 'batch' parameter\n","            # for you every time it trains.\n","            batch = tf.get_variable('batch', [],\n","                initializer=tf.constant_initializer(0), trainable=False)\n","            bn_decay = get_bn_decay(batch)\n","            tf.summary.scalar('bn_decay', bn_decay)\n","\n","            # Get model and loss \n","            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n","            MODEL.get_loss(pred, labels_pl, end_points)\n","            losses = tf.get_collection('losses')\n","            total_loss = tf.add_n(losses, name='total_loss')\n","            tf.summary.scalar('total_loss', total_loss)\n","            for l in losses + [total_loss]:\n","                tf.summary.scalar(l.op.name, l)\n","\n","            correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n","            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n","            tf.summary.scalar('accuracy', accuracy)\n","\n","            print (\"--- Get training operator\")\n","            # Get training operator\n","            learning_rate = get_learning_rate(batch)\n","            tf.summary.scalar('learning_rate', learning_rate)\n","            if OPTIMIZER == 'momentum':\n","                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n","            elif OPTIMIZER == 'adam':\n","                optimizer = tf.train.AdamOptimizer(learning_rate)\n","            train_op = optimizer.minimize(total_loss, global_step=batch)\n","            \n","            # Add ops to save and restore all the variables.\n","            saver = tf.train.Saver()\n","        \n","        # Create a session\n","        config = tf.ConfigProto()\n","        config.gpu_options.allow_growth = True\n","        config.allow_soft_placement = True\n","        config.log_device_placement = False\n","        sess = tf.Session(config=config)\n","\n","        # Add summary writers\n","        merged = tf.summary.merge_all()\n","        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'), sess.graph)\n","        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'), sess.graph)\n","\n","        # Init variables\n","        init = tf.global_variables_initializer()\n","        sess.run(init)\n","\n","        ops = {'pointclouds_pl': pointclouds_pl,\n","               'labels_pl': labels_pl,\n","               'is_training_pl': is_training_pl,\n","               'pred': pred,\n","               'loss': total_loss,\n","               'train_op': train_op,\n","               'merged': merged,\n","               'step': batch,\n","               'end_points': end_points}\n","\n","        best_acc = -1\n","        for epoch in range(MAX_EPOCH):\n","            log_string('**** EPOCH %03d ****' % (epoch))\n","            sys.stdout.flush()\n","             \n","            train_one_epoch(sess, ops, train_writer)\n","            eval_one_epoch(sess, ops, test_writer)\n","\n","            # Save the variables to disk.\n","            if epoch % 10 == 0:\n","                save_path = saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))\n","                log_string(\"Model saved in file: %s\" % save_path)\n","\n","\n","def train_one_epoch(sess, ops, train_writer):\n","    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n","    is_training = True\n","    \n","    log_string(str(datetime.now()))\n","\n","    # Make sure batch data is of same size\n","    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TRAIN_DATASET.num_channel()))\n","    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n","\n","    total_correct = 0\n","    total_seen = 0\n","    loss_sum = 0\n","    batch_idx = 0\n","    while TRAIN_DATASET.has_next_batch():\n","        batch_data, batch_label = TRAIN_DATASET.next_batch(augment=True)\n","        #batch_data = provider.random_point_dropout(batch_data)\n","        bsize = batch_data.shape[0]\n","        cur_batch_data[0:bsize,...] = batch_data\n","        cur_batch_label[0:bsize] = batch_label\n","\n","        feed_dict = {ops['pointclouds_pl']: cur_batch_data,\n","                     ops['labels_pl']: cur_batch_label,\n","                     ops['is_training_pl']: is_training,}\n","        summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n","            ops['train_op'], ops['loss'], ops['pred']], feed_dict=feed_dict)\n","        train_writer.add_summary(summary, step)\n","        pred_val = np.argmax(pred_val, 1)\n","        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n","        total_correct += correct\n","        total_seen += bsize\n","        loss_sum += loss_val\n","        if (batch_idx+1)%50 == 0:\n","            log_string(' ---- batch: %03d ----' % (batch_idx+1))\n","            log_string('mean loss: %f' % (loss_sum / 50))\n","            log_string('accuracy: %f' % (total_correct / float(total_seen)))\n","            total_correct = 0\n","            total_seen = 0\n","            loss_sum = 0\n","        batch_idx += 1\n","\n","    TRAIN_DATASET.reset()\n","        \n","def eval_one_epoch(sess, ops, test_writer):\n","    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n","    global EPOCH_CNT\n","    is_training = False\n","\n","    # Make sure batch data is of same size\n","    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TEST_DATASET.num_channel()))\n","    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n","\n","    total_correct = 0\n","    total_seen = 0\n","    loss_sum = 0\n","    batch_idx = 0\n","    shape_ious = []\n","    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n","    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n","    \n","    log_string(str(datetime.now()))\n","    log_string('---- EPOCH %03d EVALUATION ----'%(EPOCH_CNT))\n","    \n","    while TEST_DATASET.has_next_batch():\n","        batch_data, batch_label = TEST_DATASET.next_batch(augment=False)\n","        bsize = batch_data.shape[0]\n","\n","        # for the last batch in the epoch, the bsize:end are from last batch\n","        cur_batch_data[0:bsize,...] = batch_data\n","        cur_batch_label[0:bsize] = batch_label\n","        #print(\"bsize\", bsize)\n","        #print(\"Curr data\", cur_batch_data.shape)\n","        #print(\"Curr label\", cur_batch_data.shape)\n","        feed_dict = {ops['pointclouds_pl']: cur_batch_data,\n","                     ops['labels_pl']: cur_batch_label,\n","                     ops['is_training_pl']: is_training}\n","        summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n","            ops['loss'], ops['pred']], feed_dict=feed_dict)\n","        test_writer.add_summary(summary, step)\n","        pred_val = np.argmax(pred_val, 1)\n","        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n","        total_correct += correct\n","        total_seen += bsize\n","        loss_sum += loss_val\n","        batch_idx += 1\n","        for i in range(0, bsize):\n","            l = batch_label[i]\n","            total_seen_class[l] += 1\n","            total_correct_class[l] += (pred_val[i] == l)\n","    \n","    log_string('eval mean loss: %f' % (loss_sum / float(batch_idx)))\n","    log_string('eval accuracy: %f'% (total_correct / float(total_seen)))\n","    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n","    EPOCH_CNT += 1\n","\n","    TEST_DATASET.reset()\n","    return total_correct/float(total_seen)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-bdaa0f9fa684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utils'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprovider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodelnet_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'provider'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"id":"ZQ8F5aSbluaW","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","#if __name__ == \"__main__\":\n","log_string('pid: %s'%(str(os.getpid())))\n","train()\n","LOG_FOUT.close()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nu7esrpJkUUX","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"b6Cfi8aLkUz_","colab_type":"text"},"cell_type":"markdown","source":["**Evaluate the model**"]},{"metadata":{"id":"vQfWnbBcjB0Z","colab_type":"code","outputId":"0ae25b42-cc7c-4c51-aa05-dcba364242c7","executionInfo":{"status":"ok","timestamp":1539118547721,"user_tz":-120,"elapsed":1999,"user":{"displayName":"Mohammad Wasil","photoUrl":"","userId":"16449178055024790713"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"cell_type":"code","source":["'''\n","    Evaluate classification performance with optional voting.\n","    Will use H5 dataset in default. If using normal, will shift to the normal dataset.\n","'''\n","\n","# change this to False for hdf5 dataset\n","#normal = True\n","\n","BATCH_SIZE = 32\n","NUM_POINT = 200\n","\n","MODEL_PATH = '/tmp/log/model.ckpt'\n","GPU_INDEX = 0\n","NUM_VOTES = 1\n","\n","MODEL_NAME = 'pointnet2_cls_ssg'\n","MODEL = importlib.import_module('pointnet2_cls_ssg') # import network module\n","DUMP_DIR = 'dump'\n","\n","if not os.path.exists(DUMP_DIR): os.mkdir(DUMP_DIR)\n","LOG_FOUT = open(os.path.join(DUMP_DIR, 'log_evaluate.txt'), 'w')\n","#LOG_FOUT.write(str(FLAGS)+'\\n')\n","\n","#DATASET_PATH = 'shapenet_dataset/train_data_combined'\n","#DATASET_NAME = 'shapenet'\n","#CLASS_LABEL_LIST ='shape_names.txt'\n","\n","DATASET_PATH = 'gazebo_dataset_v2/gazebo_dataset_v2'\n","DATASET_NAME = 'gazebo'\n","CLASS_LABEL_LIST ='shape_names.txt'\n","\n","#DATASET_PATH = 'real_dataset'\n","#DATASET_NAME = 'atwork'\n","#CLASS_LABEL_LIST ='shape_names.txt'\n","\n","\n","SHAPE_NAMES = [line.rstrip() for line in open(os.path.join(ROOT_DIR, DATASET_PATH, CLASS_LABEL_LIST))] \n","\n","HOSTNAME = socket.gethostname()\n","\n","# Shapenet official train/test split\n","if normal:\n","    assert(NUM_POINT<=10000)\n","    DATA_PATH = os.path.join(ROOT_DIR, DATASET_PATH)\n","    TRAIN_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='train', \n","                    normal_channel=False, batch_size=BATCH_SIZE,\n","                    class_name_path=\"shape_names.txt\", dataset=DATASET_NAME)\n","    TEST_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='test', \n","                    normal_channel=False, batch_size=BATCH_SIZE,\n","                    class_name_path=\"shape_names.txt\", dataset=DATASET_NAME)\n","#else:\n","#    assert(NUM_POINT<=2048)\n","#    TRAIN_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/train_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=True)\n","#    TEST_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/test_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=False)\n","\n","NUM_CLASSES = 40\n","print(\"NUM CLASSES\", NUM_CLASSES)\n","\n","def log_string(out_str):\n","    LOG_FOUT.write(out_str+'\\n')\n","    LOG_FOUT.flush()\n","    print(out_str)\n","\n","def evaluate(num_votes):\n","    is_training = False\n","     \n","    with tf.device('/gpu:'+str(GPU_INDEX)):\n","        pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n","        is_training_pl = tf.placeholder(tf.bool, shape=())\n","\n","        # simple model\n","        pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl)\n","        MODEL.get_loss(pred, labels_pl, end_points)\n","        losses = tf.get_collection('losses')\n","        total_loss = tf.add_n(losses, name='total_loss')\n","        \n","        # Add ops to save and restore all the variables.\n","        saver = tf.train.Saver()\n","        \n","    # Create a session\n","    config = tf.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    config.allow_soft_placement = True\n","    config.log_device_placement = False\n","    sess = tf.Session(config=config)\n","\n","    # Restore variables from disk.\n","    saver.restore(sess, MODEL_PATH)\n","    log_string(\"Model restored.\")\n","\n","    ops = {'pointclouds_pl': pointclouds_pl,\n","           'labels_pl': labels_pl,\n","           'is_training_pl': is_training_pl,\n","           'pred': pred,\n","           'loss': total_loss}\n","\n","    eval_one_epoch(sess, ops, num_votes)\n","\n","def eval_one_epoch(sess, ops, num_votes=1, topk=1):\n","    is_training = False\n","\n","    # Make sure batch data is of same size\n","    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TEST_DATASET.num_channel()))\n","    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n","\n","    total_correct = 0\n","    total_seen = 0\n","    loss_sum = 0\n","    batch_idx = 0\n","    shape_ious = []\n","    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n","    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n","\n","    while TEST_DATASET.has_next_batch():\n","        batch_data, batch_label = TEST_DATASET.next_batch(augment=False)\n","        bsize = batch_data.shape[0]\n","        print('Batch: %03d, batch size: %d'%(batch_idx, bsize))\n","        # for the last batch in the epoch, the bsize:end are from last batch\n","        cur_batch_data[0:bsize,...] = batch_data\n","        cur_batch_label[0:bsize] = batch_label\n","\n","        batch_pred_sum = np.zeros((BATCH_SIZE, NUM_CLASSES)) # score for classes\n","        \n","        for vote_idx in range(num_votes):\n","            # Shuffle point order to achieve different farthest samplings\n","            shuffled_indices = np.arange(NUM_POINT)\n","            np.random.shuffle(shuffled_indices)\n","            if normal:\n","                #rotated_data = provider.rotate_point_cloud_by_angle_with_normal(cur_batch_data[:, shuffled_indices, :],\n","                #    vote_idx/float(num_votes) * np.pi * 2)\n","                rotated_data = provider.rotate_point_cloud(cur_batch_data[:, shuffled_indices, :])\n","            else:\n","                #rotated_data = provider.rotate_point_cloud_by_angle(cur_batch_data[:, shuffled_indices, :],\n","                #    vote_idx/float(num_votes) * np.pi * 2)\n","                rotated_data = provider.rotate_point_cloud(cur_batch_data[:, shuffled_indices, :])\n","            \n","            feed_dict = {ops['pointclouds_pl']: rotated_data,\n","                         ops['labels_pl']: cur_batch_label,\n","                         ops['is_training_pl']: is_training}\n","            \n","            loss_val, pred_val = sess.run([ops['loss'], ops['pred']], feed_dict=feed_dict)\n","            batch_pred_sum += pred_val\n","            \n","        pred_val = np.argmax(batch_pred_sum, 1)\n","        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n","        total_correct += correct\n","        total_seen += bsize\n","        loss_sum += loss_val\n","        batch_idx += 1\n","        for i in range(bsize):\n","            l = batch_label[i]\n","            total_seen_class[l] += 1\n","            total_correct_class[l] += (pred_val[i] == l)\n","    \n","    log_string('eval mean loss: %f' % (loss_sum / float(batch_idx)))\n","    log_string('eval accuracy: %f'% (total_correct / float(total_seen)))\n","    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class, dtype=np.float) / np.array(total_seen_class,dtype=np.float))))\n","    print(total_correct_class)\n","\n","    class_accuracies = np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float)\n","    for i, name in enumerate(SHAPE_NAMES):\n","        log_string('%10s:\\t%0.3f' % (name, class_accuracies[i]))\n","\n","\n","if __name__=='__main__':\n","    with tf.Graph().as_default():\n","        evaluate(num_votes=1)\n","    LOG_FOUT.close()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'S40_40_G': 0, 'F20_20_G': 1, 'M30': 2, 'R20': 3}\n","{'S40_40_G': 0, 'F20_20_G': 1, 'M30': 2, 'R20': 3}\n","NUM CLASSES 40\n","INFO:tensorflow:Summary name classify loss is illegal; using classify_loss instead.\n","INFO:tensorflow:Restoring parameters from /tmp/log/model.ckpt\n","Model restored.\n","Batch: 000, batch size: 28\n","eval mean loss: 0.909522\n","eval accuracy: 0.642857\n","eval avg class acc: nan\n","[6, 5, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","  S40_40_G:\t0.857\n","  F20_20_G:\t0.714\n","       M30:\t0.429\n","       R20:\t0.571\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:157: RuntimeWarning: invalid value encountered in true_divide\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:160: RuntimeWarning: invalid value encountered in true_divide\n"],"name":"stderr"}]},{"metadata":{"id":"RUciTyxrjD_g","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"aElfJgoJyWnq","colab_type":"code","outputId":"2591bbc3-f261-4194-a6ad-06a082bd535b","executionInfo":{"status":"ok","timestamp":1534006400727,"user_tz":-120,"elapsed":496,"user":{"displayName":"Mohammad Wasil","photoUrl":"//lh5.googleusercontent.com/-JLhvywYz9ws/AAAAAAAAAAI/AAAAAAAAGAI/Qh1Tzhjb9Kw/s50-c-k-no/photo.jpg","userId":"100717550650637687476"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{"tags":[]},"execution_count":63}]},{"metadata":{"id":"YG2DyIVz5-Zs","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"-XayuVQGRkj9","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"zjFBha1aRlG2","colab_type":"text"},"cell_type":"markdown","source":["**Visualization with tensorboard**"]},{"metadata":{"id":"SACNtR7ORmvD","colab_type":"code","colab":{}},"cell_type":"code","source":["LOG_DIR = '/log/train'\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-1akagqcRxvp","colab_type":"code","outputId":"1853d324-1a88-4220-9e2e-eb97d8f4a8c6","executionInfo":{"status":"ok","timestamp":1539117684454,"user_tz":-120,"elapsed":10047,"user":{"displayName":"Mohammad Wasil","photoUrl":"","userId":"16449178055024790713"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"cell_type":"code","source":["! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","! unzip ngrok-stable-linux-amd64.zip\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Redirecting output to ‘wget-log.1’.\n","Archive:  ngrok-stable-linux-amd64.zip\n","replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"metadata":{"id":"GFLAHXFxXmsg","colab_type":"code","colab":{}},"cell_type":"code","source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wwf5wKqeX_fH","colab_type":"code","outputId":"14a80bae-56a8-4cc4-9997-0b3261dcadb3","executionInfo":{"status":"ok","timestamp":1539117689235,"user_tz":-120,"elapsed":3731,"user":{"displayName":"Mohammad Wasil","photoUrl":"","userId":"16449178055024790713"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["https://6f59ba18.ngrok.io\n"],"name":"stdout"}]},{"metadata":{"id":"4kR3aDInjtij","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}